runApp('RShiny/LMMCov/LMMCov_v002')
# Load required packages
library(lme4)
library(simr)
library(simr)
# Define the number of participants and observations per condition
n_participants <- 24  # Start with 24 participants
n_conditions <- 3  # Congruent, Incongruent, Neutral
n_languages <- 2  # Dutch, English
# Create a data frame to hold simulated data
set.seed(123)  # For reproducibility
df <- expand.grid(ID = factor(1:n_participants),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
View(df)
# Add a simulated Reaction Time variable with random noise
df$RT <- rnorm(nrow(df), mean = 461, sd = 30)  # Adjust mean and sd as needed
# View the first few rows of the simulated data
head(df)
# Define the mixed model with three conditions and two languages
model <- lmer(ReactionTime ~ Condition * Language + (1 | ParticipantID), data = df)
# Define the mixed model with three conditions and two languages
model <- lmer(RT ~ Condition * Language + (1 | ParticipantID), data = df)
# Define the mixed model with three conditions and two languages
model <- lmer(RT ~ Condition * Language + (1 | ID), data = df)
# Define the mixed model with three conditions and two languages
model <- lmer(RT ~ Condition * Language + (1 | ID), data = df)
View(model)
View(model)
# Set fixed effects assuming neutral as baseline
fixef(model) <- c(Intercept = 461.0,  # Baseline for neutral condition
Conditionincongruent = 18.6,  # Effect of incongruent relative to neutral
Conditioncongruent = -10.0,  # Hypothetical effect of congruent relative to neutral
LanguageEnglish = 38.2,  # Effect of English relative to Dutch
`Conditionincongruent:LanguageEnglish` = 7.3,  # Interaction effect (incongruent x English)
`Conditioncongruent:LanguageEnglish` = 5.0)  # Hypothetical interaction effect (congruent x English)
summary(model)
# Set fixed effects assuming neutral as baseline
fixef(model) <- c((Intercept) = 461.0,  # Baseline for neutral condition
# Set fixed effects assuming neutral as baseline
fixef(model) <- c(`(Intercept)` = 461.0,  # Baseline for neutral condition
Conditionincongruent = 18.6,  # Effect of incongruent relative to neutral
Conditioncongruent = -10.0,  # Hypothetical effect of congruent relative to neutral
LanguageEnglish = 38.2,  # Effect of English relative to Dutch
`Conditionincongruent:LanguageEnglish` = 7.3,  # Interaction effect (incongruent x English)
`Conditioncongruent:LanguageEnglish` = 5.0)  # Hypothetical interaction effect (congruent x English)
# Define the mixed model with three conditions and two languages
model <- lmer(RT ~ factor(Condition) * factor(Language) + (1 | ID), data = df)
# Set fixed effects assuming neutral as baseline
fixef(model) <- c(`(Intercept)` = 461.0,  # Baseline for neutral condition
Conditionincongruent = 18.6,  # Effect of incongruent relative to neutral
Conditioncongruent = -10.0,  # Hypothetical effect of congruent relative to neutral
LanguageEnglish = 38.2,  # Effect of English relative to Dutch
`Conditionincongruent:LanguageEnglish` = 7.3,  # Interaction effect (incongruent x English)
`Conditioncongruent:LanguageEnglish` = 5.0)  # Hypothetical interaction effect (congruent x English)
fixef(model) <- c(Condition = 18.6)
fixef(model)["Condition"] <- 18.6
fixef(model)["Condition"]
fixef(model)["Conditionincongruent"]
# Simulate power for the interaction term between Condition and Language
power_analysis <- powerSim(model, nsim = 1000, test = fixed("Condition", "t"))
print(power_analysis)
install.packages("nlmeU")
library(nlme)
# Define a sample mixed-effects model
model <- lme(RT ~ Condition * Language,
random = ~ 1 | ID,
data = df)
# Define simulation parameters
n_sim <- 1000
sample_sizes <- seq(20, 100, 10)  # Example range of sample sizes
# Function to simulate and fit model
simulate_power <- function(n) {
df <- expand.grid(ID = factor(1:n),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
df$RT <- rnorm(nrow(df), mean = 461, sd = 30)
model <- lme(ReactionTime ~ Condition * Language,
random = ~ 1 | ID,
data = df)
# Extract p-value for interaction term
summary(model)$tTable["Condition:Language", "p-value"]
}
# Run simulation
power_estimates <- sapply(sample_sizes, function(n) {
p_vals <- replicate(n_sim, simulate_power(n))
mean(p_vals < 0.05)  # Proportion of significant p-values
})
# Function to simulate and fit model
simulate_power <- function(n) {
df <- expand.grid(ID = factor(1:n),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
df$RT <- rnorm(nrow(df), mean = 461, sd = 30)
model <- lme(RT ~ Condition * Language,
random = ~ 1 | ID,
data = df)
# Extract p-value for interaction term
summary(model)$tTable["Condition:Language", "p-value"]
}
# Run simulation
power_estimates <- sapply(sample_sizes, function(n) {
p_vals <- replicate(n_sim, simulate_power(n))
mean(p_vals < 0.05)  # Proportion of significant p-values
})
# Plot the results
plot(sample_sizes, power_estimates, type = "b", ylim = c(0, 1),
xlab = "Sample Size", ylab = "Estimated Power")
# Define simulation parameters
n_sim <- 1000
sample_sizes <- seq(20, 100, 10)  # Example range of sample sizes
# Function to simulate and fit model
simulate_power <- function(n) {
df <- expand.grid(ID = factor(1:n),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
df$RT <- rnorm(nrow(df), mean = 461, sd = 30)
model <- lme(RT ~ Condition * Language,
random = ~ 1 | ID,
data = df)
# Extract p-value for interaction term
summary(model)$tTable["Condition:Language", "p-value"]
}
# Run simulation
power_estimates <- sapply(sample_sizes, function(n) {
p_vals <- replicate(n_sim, simulate_power(n))
mean(p_vals < 0.05)  # Proportion of significant p-values
})
# Function to simulate and fit model
simulate_power <- function(n) {
df <- expand.grid(ID = factor(1:n),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
df$RT <- rnorm(nrow(df), mean = 461, sd = 30)
model <- lme(RT ~ Condition * Language,
random = ~ 1 | ID,
data = df)
# Extract p-value for interaction term
summary(model)$tTable["Conditionincongruent:LanguageEnglish", "p-value"]
}
# Run simulation
power_estimates <- sapply(sample_sizes, function(n) {
p_vals <- replicate(n_sim, simulate_power(n))
mean(p_vals < 0.05)  # Proportion of significant p-values
})
# Plot the results
plot(sample_sizes, power_estimates, type = "b", ylim = c(0, 1),
xlab = "Sample Size", ylab = "Estimated Power")
abline(h = 0.8, col = "red")
# Function to simulate and fit model
simulate_power <- function(n) {
df <- expand.grid(ID = factor(1:n),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
df$RT <- rnorm(nrow(df), mean = 461, sd = 30)
model <- lme(RT ~ Condition * Language,
random = ~ 1 | ID,
data = df)
# Extract p-value for interaction term
summary(model)$tTable["Conditionincongruent", "p-value"]
}
# Run simulation
power_estimates <- sapply(sample_sizes, function(n) {
p_vals <- replicate(n_sim, simulate_power(n))
mean(p_vals < 0.05)  # Proportion of significant p-values
})
# Plot the results
plot(sample_sizes, power_estimates, type = "b", ylim = c(0, 1),
xlab = "Sample Size", ylab = "Estimated Power")
abline(h = 0.8, col = "red")
fm1 <- lmer(RT ~ Condition + (1|Language), data=df)
# Define the number of participants and observations per condition
n_participants <- 24  # Start with 24 participants
n_conditions <- 3  # Congruent, Incongruent, Neutral
n_languages <- 2  # Dutch, English
# Create a data frame to hold simulated data
set.seed(123)  # For reproducibility
df <- expand.grid(ID = factor(1:n_participants),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
# Add a simulated ReactionTime variable with random noise
df$RT <- rnorm(nrow(df), mean = 461, sd = 30)  # Adjust mean and sd as needed
fm1 <- lmer(RT ~ Condition + (1|Language), data=df)
powerSim(fm1, nsim=10)
powerSim(fm1, nsim=1000)
fm1 <- lmer(RT ~ Condition + Language + (1|ID), data=df)
powerSim(fm1, nsim=1000)
n_participants <- 60  # Start with 24 participants
n_conditions <- 3  # Congruent, Incongruent, Neutral
n_languages <- 2  # Dutch, English
# Create a data frame to hold simulated data
set.seed(123)  # For reproducibility
df <- expand.grid(ID = factor(1:n_participants),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
# Add a simulated ReactionTime variable with random noise
df$RT <- rnorm(nrow(df), mean = 461, sd = 69.1)  # Adjust mean and sd as needed
fm1 <- lmer(RT ~ Condition + Language + (1|ID), data=df)
powerSim(fm1, nsim=2000)
powerCurve(fm1)
n_participants <- 100  # Start with 24 participants
n_conditions <- 3  # Congruent, Incongruent, Neutral
n_languages <- 2  # Dutch, English
# Create a data frame to hold simulated data
set.seed(123)  # For reproducibility
df <- expand.grid(ID = factor(1:n_participants),
Condition = factor(c("congruent", "incongruent", "neutral")),
Language = factor(c("Dutch", "English")))
# Add a simulated ReactionTime variable with random noise
df$RT <- rnorm(nrow(df), mean = 461, sd = 69.1)  # Adjust mean and sd as needed
fm1 <- lmer(RT ~ Condition + Language + (1|ID), data=df)
powerSim(fm1, nsim=2000)
# Define parameters
effect_size <- 0.3  # Example effect size (can be adjusted based on prior knowledge)
library(samplesizeMixed)
###################################
install.packages("samplesizeMixed")
library(samplesizeMixed)
###################################
install.packages("samplesize_mixed")
library(sjstats)
# Estimate the required sample size (number of participants)
result <- samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
delta = effect_size,
ICC = ICC,
alpha = alpha,
power = power)
samplesize_mixed(eff.size = .3, n = 6)
samplesize_mixed(eff.size = .3, k = 54)
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = effect_size,
icc = ICC,
sig.level = alpha,
power = power)
effect_size <- 0.3  # Example effect size (can be adjusted based on prior knowledge)
ICC <- 0.5  # Assumed intraclass correlation
n <- 6  # 3 conditions * 2 languages = 6 measurements per participant
alpha <- 0.05
power <- 0.80
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = effect_size,
icc = ICC,
sig.level = alpha,
power = power)
effect_size <- 0.5
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = effect_size,
icc = ICC,
sig.level = alpha,
power = power)
effect_size <- 0.4
result <- samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = effect_size,
icc = ICC,
sig.level = alpha,
power = power)
print(result)
effect_size <- 0.4  # Example effect size (can be adjusted based on prior knowledge)
ICC <- 0.05  # Assumed intraclass correlation
n <- 6  # 3 conditions * 2 languages = 6 measurements per participant
alpha <- 0.05
power <- 0.80
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = effect_size,
icc = ICC,
sig.level = alpha,
power = power)
effect_size <- 0.3  # Example effect size (can be adjusted based on prior knowledge)
ICC <- 0.05  # Assumed intraclass correlation
n <- 6  # 3 conditions * 2 languages = 6 measurements per participant
alpha <- 0.05
power <- 0.80
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = effect_size,
icc = ICC,
sig.level = alpha,
power = power)
effect_size <- 0.3  # Example effect size (can be adjusted based on prior knowledge)
#ICC <- 0.05  # Assumed intraclass correlation
n <- 6  # 3 conditions * 2 languages = 6 measurements per participant
alpha <- 0.05
power <- 0.80
# Estimate the required sample size (number of participants)
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = effect_size,
#icc = ICC,
sig.level = alpha,
power = power)
# Define parameters
efs <- 0.3  # Example effect size (can be adjusted based on prior knowledge)
n <- 6  # 3 conditions * 2 languages = 6 measurements per participant
alpha <- 0.05
power <- 0.80
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = efs,
sig.level = alpha,
power = power)
efs <- 0.2  # Example effect size (can be adjusted based on prior knowledge)
n <- 6  # 3 conditions * 2 languages = 6 measurements per participant
alpha <- 0.05
power <- 0.80
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = efs,
sig.level = alpha,
power = power)
efs <- 0.4  # Example effect size (can be adjusted based on prior knowledge)
n <- 6  # 3 conditions * 2 languages = 6 measurements per participant
alpha <- 0.05
power <- 0.80
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = efs,
sig.level = alpha,
power = power)
efs <- 0.5  # Example effect size (can be adjusted based on prior knowledge)
n <- 6  # 3 conditions * 2 languages = 6 measurements per participant
alpha <- 0.05
power <- 0.80
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = efs,
sig.level = alpha,
power = power)
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = 0.2,
sig.level = alpha,
power = 0.9)
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = 0.3,
sig.level = alpha,
power = 0.9)
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = 0.4,
sig.level = alpha,
power = 0.9)
samplesize_mixed(k = NULL,  # Set to NULL to estimate it
n = n,
eff.size = 0.5,
sig.level = alpha,
power = 0.9)
effect_size <- 0.3  # Adjust based on your understanding of the effect size
sample_size <- 88
alpha <- 0.05
regression)
# Power calculation using pwr.f2.test (f2 is an approximation for effect size in logistic regression)
pwr_result <- pwr.f2.test(u = 8,  # Number of predictors (including binary, ordinal, and ratio)
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = effect_size / (1 - effect_size),  # Convert effect size to f2
sig.level = alpha,
power = NULL)  # Power will be calculated
library(pwr)
# Power calculation using pwr.f2.test (f2 is an approximation for effect size in logistic regression)
pwr_result <- pwr.f2.test(u = 8,  # Number of predictors (including binary, ordinal, and ratio)
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = effect_size / (1 - effect_size),  # Convert effect size to f2
sig.level = alpha,
power = NULL)  # Power will be calculated
# Print power
pwr_result
effect_size <- 1.5
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = effect_size / (1 - effect_size),  # Convert effect size to f2
sig.level = alpha,
power = NULL)
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = 1.5,  # Convert effect size to f2
sig.level = alpha,
power = NULL)
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = 0.5,  # Convert effect size to f2
sig.level = alpha,
power = NULL)
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = 0.1,  # Convert effect size to f2
sig.level = alpha,
power = NULL)
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = 0.2,  # Convert effect size to f2
sig.level = alpha,
power = NULL)
# Assuming a small effect size for logistic regression
effect_size <- 0.8  # Adjust based on your understanding of the effect size
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = effect_size / (1 - effect_size),  # Convert effect size to f2
sig.level = alpha,
power = NULL)
# Assuming a small effect size for logistic regression
effect_size <- 0.2  # Adjust based on your understanding of the effect size
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = effect_size / (1 - effect_size),  # Convert effect size to f2
sig.level = alpha,
power = NULL)
# Assuming a small effect size for logistic regression
effect_size <- 0.1  # Adjust based on your understanding of the effect size
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = effect_size / (1 - effect_size),  # Convert effect size to f2
sig.level = alpha,
power = NULL)
# Assuming a small effect size for logistic regression
effect_size <- 0.15  # Adjust based on your understanding of the effect size
pwr.f2.test(u = 8,  # Number of predictors
v = sample_size - 8 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = effect_size / (1 - effect_size),  # Convert effect size to f2
sig.level = alpha,
power = NULL)
library(effectsize)
effect_size <- 0.15
pwr.f2.test(u = 2,  # Number of predictors
v = sample_size - 2 - 1,  # Degrees of freedom (n - number of predictors - 1)
f2 = effect_size / (1 - effect_size),  # Convert effect size to f2
sig.level = alpha,
power = NULL)
setwd("~/Statistical Consultancy/Liza De Dobbeleer _ FORTO 2_0")
load("~/Statistical Consultancy/Liza De Dobbeleer _ FORTO 2_0/gw.ls/gw.ls_UZB_from_sid4to_sid125.rdata")
View(gw.ls.UZB)
names(gw.ls.UZB)
styler:::style_selection()
gw.ls.UZB.filtered <- subset(gw.ls.UZB, select = c(sid, i_rep, n_reps, setting, device, SubjectId, FR, FR_alta, FR_reported, GW_c_MaxGS_overall, GW_i.f, GW_i.uf))
library(dplyr)
# Sort data
sorted_data <- gw.ls.UZB.filtered |>
arrange(sid)
# Sort data
sorted_data <- gw.ls.UZB.filtered |>
dplyr::arrange(sid)
# Identify rows where the absolute difference between 'FR' and 'FR_reported' is greater than 5
problematic_rows <- gw.ls.UZB.filtered |>
group_by(sid) |> # Grouping by 'sid' to check within each subject
filter(abs(FR - FR_reported) > 5) |> # Filter rows where the difference is more than 5
select(sid, i_rep, FR, FR_reported) # Select relevant columns to display
View(gw.ls.UZB.filtered)
View(gw.ls.UZB.filtered)
View(gw.ls.UZB)
View(gw.ls.UZB.filtered)
View(gw.ls.UZB.filtered)
View(gw.ls.UZB.filtered)
View(gw.ls.UZB.filtered)
# Sort data
sorted_data <- gw.ls.UZB.filtered |>
arrange(sid)
library(dplyr)
# Sort data
sorted_data <- gw.ls.UZB.filtered |>
arrange(sid)
View(gw.ls.UZB.filtered)
gw.ls.UZB.filtered <- subset(gw.ls.UZB, select = c(sid, i_rep, n_reps, setting, device, SubjectId, FR, FR_alta, FR_reported, GW_c_MaxGS_overall, GW_i.f, GW_i.uf))
View(gw.ls.UZB.filtered)
# Identify rows where the absolute difference between 'FR' and 'FR_reported' is greater than 5
problematic_rows <- gw.ls.UZB.filtered |>
group_by(sid) |> # Grouping by 'sid' to check within each subject
filter(abs(FR - FR_reported) > 5) |> # Filter rows where the difference is more than 5
select(sid, i_rep, FR, FR_reported) # Select relevant columns to display
# Display the problematic rows
print(problematic_rows)
View(problematic_rows)
gw.ls.UZB.filtered <- subset(gw.ls.UZB, select = c(sid, i_rep, n_reps, setting, device, SubjectId, FR, FR_alta, FR_reported, GW_c_MaxGS_overall, GW_i.f, GW_i.uf))
# Identify rows where the absolute difference between 'FR' and 'FR_reported' is greater than 5
problematic_rows <- gw.ls.UZB.filtered |>
group_by(sid) |> # Grouping by 'sid' to check within each subject
filter(abs(FR - FR_reported) > 5) |> # Filter rows where the difference is more than 5
select(sid, i_rep, setting, device, FR, FR_reported, GW_c_MaxGS_overall, GW_i.f, GW_i.uf) # Select relevant columns to display
View(problematic_rows)
gw.ls.UZB.filtered <- subset(gw.ls.UZB, select = c(sid, i_rep, n_reps, setting, device, SubjectId, FR, FR_alta, FR_reported, GW_c_MaxGS_overall, GW_i.f, GW_i.uf))
# Identify rows where the absolute difference between 'FR' and 'FR_reported' is greater than 5
problematic_rows <- gw.ls.UZB.filtered |>
group_by(sid) |> # Grouping by 'sid' to check within each subject
filter(abs(FR - FR_reported) > 5) |> # Filter rows where the difference is more than 5
select(sid, i_rep, setting, device, FR, FR_reported, GW_c_MaxGS_overall, GW_i.uf) # Select relevant columns to display
gw.ls.UZB.filtered <- subset(gw.ls.UZB, select = c(sid, i_rep, n_reps, setting, device, SubjectId, FR, FR_alta, FR_reported, GW_c_MaxGS_overall, GW_i.f, GW_i.uf))
# Identify rows where the absolute difference between 'FR' and 'FR_reported' is greater than 5
problematic_rows <- gw.ls.UZB.filtered |>
group_by(sid) |> # Grouping by 'sid' to check within each subject
filter(abs(FR - FR_reported) > 5) |> # Filter rows where the difference is more than 5
select(sid, i_rep, setting, device, FR, FR_alta, FR_reported, GW_c_MaxGS_overall, GW_i.uf) # Select relevant columns to display
# Identify rows where the absolute difference between 'FR' and 'FR_reported' is greater than 5
problematic_rows <- gw.ls.UZB.filtered |>
group_by(sid) |> # Grouping by 'sid' to check within each subject
filter(abs(FR - FR_reported) > 5) |> # Filter rows where the difference is more than 5
select(sid, i_rep, setting, device, FR, FR_reported, GW_c_MaxGS_overall, GW_i.uf) # Select relevant columns to display
unique(problematic_rows$sid)
unique(problematic_rows$sid)
save(problematic_rows, file = "problematic_rows.RData")
load("~/Statistical Consultancy/Liza De Dobbeleer _ FORTO 2_0/problematic_rows.RData")
View(problematic_rows)
load("~/Statistical Consultancy/Liza De Dobbeleer _ FORTO 2_0/problematic_rows.RData")
View(problematic_rows)
write.csv(problematic_rows, file = "problematic_rows.csv")
setwd("~/RShiny/ReDiag/Final (new data)/ReDiag app - Revised")
shiny::runApp()
setwd("~/RShiny/LMMCov/LMMCov_v002")
runApp()
